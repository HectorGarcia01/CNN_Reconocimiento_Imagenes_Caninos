{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importamos las librerias"
      ],
      "metadata": {
        "id": "SDFuoO5paNFZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hBCdEFMLaI9z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras import optimizers, regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as k\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Limpiamos todas las sesiones para tener más rendimiento\n"
      ],
      "metadata": {
        "id": "z8kJVbGbRfwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k.clear_session()"
      ],
      "metadata": {
        "id": "D5Ze_i69Rno6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Para conectarnos con google drive"
      ],
      "metadata": {
        "id": "5ZBlZXPBXoMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwDZUV3gXe9S",
        "outputId": "761823c8-dc86-4e8a-be1b-a214418834de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descomprimiendo los archivos ZIP de nuestro set de datos"
      ],
      "metadata": {
        "id": "VqF0tNXOZdf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Caninos.zip -d /content/"
      ],
      "metadata": {
        "id": "8b5pZQC3Zd2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definimos la ruta del set de datos tanto de entrenamiento como de validación"
      ],
      "metadata": {
        "id": "0I0_m5F1d4im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ruta de la carpeta con las imágenes de entrenamiento\n",
        "data_entrenamiento = '/content/Caninos/train'\n",
        "\n",
        "#Ruta de la carpeta con las imágenes de validación\n",
        "data_validacion = '/content/Caninos/val'"
      ],
      "metadata": {
        "id": "r60cQ4pXd31Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Contando el número de imágenes y clases del set de datos"
      ],
      "metadata": {
        "id": "1du-ykQpc1aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Variables para guardar el numero de clases para entrenamiento y validación\n",
        "num_clases_entrenamiento = 0\n",
        "num_clases_validacion = 0\n",
        "\n",
        "#Variables para guardar el numero de imagenes para entrenamiento y validación\n",
        "num_imagenes_entrenamiento = 0\n",
        "num_imagenes_validacion = 0\n",
        "\n",
        "#Recorremos cada subcarpeta de la ruta de entrenamiento\n",
        "for root, dirs, files in os.walk(data_entrenamiento):\n",
        "    for dir in dirs:\n",
        "        carpeta_ruta = os.path.join(root, dir)\n",
        "        num_imagenes = len(os.listdir(carpeta_ruta)) #Obtenemos el total de imagenes para x clase\n",
        "        num_clases_entrenamiento += 1 #Aumentamos el número de clases\n",
        "        num_imagenes_entrenamiento = num_imagenes_entrenamiento + num_imagenes #Aumentamos el total de imagenes por cada clase\n",
        "        print(f'El número de imágenes en la carpeta {carpeta_ruta} es: {num_imagenes}')\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Recorremos cada subcarpeta de la ruta de validación\n",
        "for root, dirs, files in os.walk(data_validacion):\n",
        "    for dir in dirs:\n",
        "        carpeta_ruta = os.path.join(root, dir)\n",
        "        num_imagenes = len(os.listdir(carpeta_ruta))  #Obtenemos el total de imagenes para x clase\n",
        "        num_clases_validacion += 1 #Aumentamos el número de clases\n",
        "        num_imagenes_validacion = num_imagenes_validacion + num_imagenes #Aumentamos el total de imagenes por cada clase\n",
        "        print(f'El número de imágenes en la carpeta {carpeta_ruta} es: {num_imagenes}')\n",
        "\n",
        "#Mostramos el numero de clases y el numero de imagenes de entrenamiento\n",
        "print(f'\\n\\nEl número de clases en la carpeta {data_entrenamiento} es: {num_clases_entrenamiento}')\n",
        "print(f'El número de imagenes de entrenamiento es: {num_imagenes_entrenamiento}')\n",
        "\n",
        "#Mostramos el numero de clases y el numero de imagenes de validación\n",
        "print(f'\\n\\nEl número de clases en la carpeta {data_validacion} es: {num_clases_validacion}')\n",
        "print(f'El número de imagenes de validación es: {num_imagenes_validacion}')"
      ],
      "metadata": {
        "id": "V6sk1AfOc3Ie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b2165bc-139c-4f7d-b447-13a8c1d2b534"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número de imágenes en la carpeta /content/Caninos/train/perro es: 716\n",
            "El número de imágenes en la carpeta /content/Caninos/train/lobo es: 431\n",
            "El número de imágenes en la carpeta /content/Caninos/train/coyote es: 471\n",
            "El número de imágenes en la carpeta /content/Caninos/train/zorro es: 651\n",
            "\n",
            "\n",
            "\n",
            "El número de imágenes en la carpeta /content/Caninos/val/perro es: 364\n",
            "El número de imágenes en la carpeta /content/Caninos/val/lobo es: 104\n",
            "El número de imágenes en la carpeta /content/Caninos/val/coyote es: 218\n",
            "El número de imágenes en la carpeta /content/Caninos/val/zorro es: 129\n",
            "\n",
            "\n",
            "El número de clases en la carpeta /content/Caninos/train es: 4\n",
            "El número de imagenes de entrenamiento es: 2269\n",
            "\n",
            "\n",
            "El número de clases en la carpeta /content/Caninos/val es: 4\n",
            "El número de imagenes de validación es: 815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definimos parámetros e hiperparámetros para la CNN"
      ],
      "metadata": {
        "id": "ZDG-SpZmaRbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "altura, longitud = 150, 150 #Tamaño de las imágenes que se utilizarán\n",
        "batch_size = 32 #Tamaño del lote para el entrenamiento\n",
        "epocas = 150 #Cantidad de épocas para entrenar\n",
        "pasos = num_imagenes_entrenamiento//batch_size #Número de pasos de entrenamiento por época\n",
        "validation_steps = num_imagenes_validacion//batch_size #Número de pasos de validación por épocas\n",
        "filtros_Conv1 = 64 #Número de filtros para la primera capa convolucional\n",
        "filtros_Conv2 = 128 #Número de filtros para la segunda capa convolucional\n",
        "filtros_Conv3 = 256 #Número de filtros para la tercera capa convolucional\n",
        "filtros_Conv4 = 512 #Número de filtros para la cuarta capa convolucional\n",
        "filtros_Conv5 = 512 #Número de filtros para la quinta capa convolucional\n",
        "tamanio_filtro1 = (3, 3) #Tamaño del filtro para la primera capa convolucional\n",
        "tamanio_filtro2 = (3, 3) #Tamaño del filtro para la segunda capa convolucional\n",
        "tamanio_filtro3 = (3, 3) #Tamaño del filtro para la tercera capa convolucional\n",
        "tamanio_filtro4 = (3, 3) #Tamaño del filtro para la cuarta capa convolucional\n",
        "tamanio_filtro5 = (3, 3) #Tamaño del filtro para la quinta capa convolucional\n",
        "tamanio_pool = (2, 2) #Tamaño de pool de agrupación\n",
        "clases = 4 #Número de clases (perro, zorro, lobo y coyote)\n",
        "lr = 0.0004 #Tasa de aprendizaje"
      ],
      "metadata": {
        "id": "MpNmAAX7aWET"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definimos el ImageDataGenerator para la generación de imágenes y ajuste"
      ],
      "metadata": {
        "id": "B7s9OlCfao42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generación de datos de imágenes y ajuste para entrenamiento\n",
        "entrenamiento_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,               #Reescala los valores de píxeles para que estén en el rango [0, 1]\n",
        "    rotation_range=10,            #Rango de ángulos en grados para rotar aleatoriamente las imágenes\n",
        "    vertical_flip=True,           #Voltea verticalmente las imágenes de forma aleatoria\n",
        "    width_shift_range=0.3,        #Desplazamiento aleatorio horizontal en fracción de la anchura total de la imagen\n",
        "    height_shift_range=0.1,       #Desplazamiento aleatorio vertical en fracción de la altura total de la imagen\n",
        "    channel_shift_range=0.2,      #Desplazamiento aleatorio de los canales de color\n",
        "    shear_range=0.2,              #Rango de ángulos en grados para realizar transformaciones de cizallamiento\n",
        "    zoom_range=0.2,               #Rango de zoom aleatorio para las imágenes\n",
        "    horizontal_flip=True,         #Voltea horizontalmente las imágenes de forma aleatoria\n",
        "    brightness_range=(0.8, 1.2),  #Rango de brillo aleatorio para las imágenes\n",
        "    fill_mode='nearest')          #Modo de relleno para los píxeles cuando se aplican transformaciones de tamaño o posición\n",
        "\n",
        "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
        "    data_entrenamiento,\n",
        "    target_size=(longitud, altura),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "#Generación de datos de imágenes y ajuste para validación\n",
        "validacion_datagen = ImageDataGenerator(rescale=1./255) #Solo se reescalan los valores de píxeles para la validación\n",
        "\n",
        "validacion_generador = validacion_datagen.flow_from_directory(\n",
        "    data_validacion,\n",
        "    target_size=(longitud, altura),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "id": "JELsDB92a0st",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ca4fe0-3ef4-4547-c54a-41d66b65a5a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2269 images belonging to 4 classes.\n",
            "Found 815 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Obtenemos los nombres de las clases y las guardamos en un archivo json para usarlo en un archivo aparte para la predicción"
      ],
      "metadata": {
        "id": "8wueah7qBTf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtenemos los nombres de las clases\n",
        "nombre_clases = entrenamiento_generador.class_indices\n",
        "\n",
        "#Guardamos los nombres de las clases en un archivo JSON\n",
        "with open('clases_Canino.json', 'w') as f:\n",
        "    json.dump(nombre_clases, f)\n"
      ],
      "metadata": {
        "id": "fpoVrJo4Bc4d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definimos la arquitectura de la CNN"
      ],
      "metadata": {
        "id": "ELL6O33baYBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creación del modelo utilizando la arquitectura VGG16\n",
        "modelo = Sequential()\n",
        "\n",
        "#Primera apa de convolución y pooling\n",
        "modelo.add(Conv2D(filtros_Conv1, tamanio_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu'))\n",
        "modelo.add(Conv2D(filtros_Conv1, tamanio_filtro1, padding =\"same\", activation='relu'))\n",
        "modelo.add(MaxPooling2D(pool_size=tamanio_pool))\n",
        "\n",
        "#Segunda capa de convolución y pooling\n",
        "modelo.add(Conv2D(filtros_Conv2, tamanio_filtro2, padding=\"same\", activation='relu'))\n",
        "modelo.add(Conv2D(filtros_Conv2, tamanio_filtro2, padding=\"same\", activation='relu'))\n",
        "modelo.add(MaxPooling2D(pool_size=tamanio_pool))\n",
        "\n",
        "#Tercera capa de convolución y pooling\n",
        "modelo.add(Conv2D(filtros_Conv3, tamanio_filtro3, padding=\"same\", activation='relu'))\n",
        "modelo.add(Conv2D(filtros_Conv3, tamanio_filtro3, padding=\"same\", activation='relu'))\n",
        "modelo.add(MaxPooling2D(pool_size=tamanio_pool))\n",
        "\n",
        "#Cuarta capa de convolución y pooling\n",
        "modelo.add(Conv2D(filtros_Conv4, tamanio_filtro4, padding=\"same\", activation='relu'))\n",
        "modelo.add(Conv2D(filtros_Conv4, tamanio_filtro4, padding=\"same\", activation='relu'))\n",
        "modelo.add(MaxPooling2D(pool_size=tamanio_pool))\n",
        "\n",
        "#Quinta capa de convolución y pooling\n",
        "modelo.add(Conv2D(filtros_Conv5, tamanio_filtro5, padding=\"same\", activation='relu'))\n",
        "modelo.add(Conv2D(filtros_Conv5, tamanio_filtro5, padding=\"same\", activation='relu'))\n",
        "modelo.add(MaxPooling2D(pool_size=tamanio_pool))\n",
        "\n",
        "#Capa completamente conectada\n",
        "modelo.add(Flatten())\n",
        "modelo.add(Dense(4096, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "modelo.add(Dropout(0.5))\n",
        "modelo.add(Dense(4096, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "modelo.add(Dropout(0.5))\n",
        "modelo.add(Dense(clases, activation='softmax'))"
      ],
      "metadata": {
        "id": "LEVIk37najkk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compilamos el modelo"
      ],
      "metadata": {
        "id": "V7N2gliDbEo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=lr),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mF4ZoUWZbKiB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizamos el callback \"checkpoint\" y el callback \"earlystopping\" para guardar el modelo con mejor rendimiento y con una paciencia de 10"
      ],
      "metadata": {
        "id": "4JMBoMy5bMdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuramos el callback chekpoint (content/Mejor_Modelo/modelo_caninos.h5)\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/modelo_caninos.h5', \n",
        "                             monitor='val_accuracy', \n",
        "                             mode='max', \n",
        "                             save_best_only=True, \n",
        "                             verbose=1)\n",
        "\n",
        "#Configuramos el callback earlystopping\n",
        "earlystopping = EarlyStopping(monitor='val_accuracy',\n",
        "                              patience=10,\n",
        "                              verbose=1)\n",
        "\n",
        "#Unimos ambos callbacks\n",
        "callbacks = [checkpoint, earlystopping]"
      ],
      "metadata": {
        "id": "307686m9bYRJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamos el modelo"
      ],
      "metadata": {
        "id": "PwKId_cSbdfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "historial_entrenamiento = modelo.fit(\n",
        "    entrenamiento_generador,\n",
        "    steps_per_epoch=pasos,\n",
        "    epochs=epocas,\n",
        "    validation_data=validacion_generador,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "8vpvwHJHbj3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3568e91-95d7-43f2-aaab-55a0888620a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "14/70 [=====>........................] - ETA: 23s - loss: 72.7094 - accuracy: 0.2545"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - ETA: 0s - loss: 27.8050 - accuracy: 0.3026\n",
            "Epoch 1: val_accuracy improved from -inf to 0.44750, saving model to /content/drive/MyDrive/modelo_caninos.h5\n",
            "70/70 [==============================] - 83s 864ms/step - loss: 27.8050 - accuracy: 0.3026 - val_loss: 3.4964 - val_accuracy: 0.4475\n",
            "Epoch 2/150\n",
            "65/70 [==========================>...] - ETA: 3s - loss: 2.1969 - accuracy: 0.3067"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cargamos el mejor modelo obtenido"
      ],
      "metadata": {
        "id": "GHdJOL0JMIxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_cargado = load_model('/content/drive/MyDrive/modelo_caninos.h5')#Cargar el modelo guardado desde nuestro drive\n",
        "#modelo_cargado = load_model(/content/Mejor_Modelo/modelo_caninos.h5) #Cargar el modelo desde la carpeta Mejor_Modelo"
      ],
      "metadata": {
        "id": "9kBC81EPMRqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Obtenemos el accuracy y loss del historial de entrenamiento"
      ],
      "metadata": {
        "id": "aXpRILZ-NAEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obtener_metricas = historial_entrenamiento.history\n",
        "\n",
        "#Mostramos las métricas del historial\n",
        "print(obtener_metricas.keys())"
      ],
      "metadata": {
        "id": "20SkfYu1NszA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graficamos las metricas accuracy y loss de los datos de entrenamiento"
      ],
      "metadata": {
        "id": "1LSUHgw0Ozpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Trazamos la curva de pérdida obtenida durante el entrenamiento\n",
        "plt.plot(obtener_metricas['loss'], 'ro--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.title('Curva de pérdida - Entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "#Trazamos la curva de precisión obtenida durante el entrenamiento\n",
        "plt.plot(obtener_metricas['accuracy'], 'go--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Curva de precisión - Entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "#Trazamos la curva de pérdida y la curva de precisión para entrenamiento\n",
        "plt.plot(obtener_metricas['loss'], 'ro--')\n",
        "plt.plot(obtener_metricas['accuracy'], 'go--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida/Precisión')\n",
        "plt.title('Curva de precisión/pérdida - Entrenamiento')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "brvDxmgGO5gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graficamos las metricas accuracy y loss de los datos de validación"
      ],
      "metadata": {
        "id": "5yyZO7Z4moY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Trazamos la curva de pérdida de validación obtenida durante el entrenamiento\n",
        "plt.plot(obtener_metricas['val_loss'], 'ro--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.title('Curva de pérdida - Validación')\n",
        "plt.show()\n",
        "\n",
        "#Trazamos la curva de precisión de validación obtenida durante el entrenamiento\n",
        "plt.plot(obtener_metricas['val_accuracy'], 'go--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Curva de precisión - Validación')\n",
        "plt.show()\n",
        "\n",
        "#Trazamos la curva de pérdida y la curva de precisión para validación\n",
        "plt.plot(obtener_metricas['val_loss'], 'ro--')\n",
        "plt.plot(obtener_metricas['val_accuracy'], 'go--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida/Precisión')\n",
        "plt.title('Curva de precisión/pérdida - Validación')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bgN4AlmfmrlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Realizamos una predicción de alguna imágen del set de datos de validación"
      ],
      "metadata": {
        "id": "ImV2GDLNb9lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos una imagen del set de validación\n",
        "ruta_imagen = '/content/Caninos/val/perro/perro_val_30.jpg'\n",
        "img = load_img(ruta_imagen, target_size=(altura, longitud))\n",
        "\n",
        "#Convertimos la imagen a un array de NumPy\n",
        "img_array = img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "#Hacemos la predicción con el modelo\n",
        "prediccion = modelo_cargado.predict(img_array)\n",
        "\n",
        "#Obtener las probabilidades de pertenencia a cada clase y aplicar la función softmax\n",
        "probabilidades = softmax(prediccion)[0]\n",
        "\n",
        "#Obtener los nombres de las clases\n",
        "nombre_clases = entrenamiento_generador.class_indices.keys()\n",
        "\n",
        "#Imprimimos las clases de felinos\n",
        "print(nombre_clases)\n",
        "\n",
        "#Imprimir los porcentajes de pertenencia a cada clase\n",
        "for i, name in enumerate(nombre_clases):\n",
        "    print(f\"{name}: {probabilidades[i]*100:.2f}%\")"
      ],
      "metadata": {
        "id": "xz6wt9i4551E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Opcional\n",
        "En caso de no quedar satisfecho con el entrenamiento y se quiera volver a entrenar el mejor modelo del entrenamiento anterior y así no iniciar de cero."
      ],
      "metadata": {
        "id": "WZdqIwiG3Fqq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCb_qr303vRs"
      },
      "outputs": [],
      "source": [
        "historial_modelo_cargado = modelo_cargado.fit(\n",
        "    entrenamiento_generador,\n",
        "    steps_per_epoch=pasos,\n",
        "    epochs=epocas,\n",
        "    validation_data=validacion_generador,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LbKZc443kUv"
      },
      "source": [
        "#Opcional\n",
        "Obtenemos el accuracy y loss del historial de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFImx9ZG3kUw"
      },
      "outputs": [],
      "source": [
        "obtener_metricas_modelo_nuevo = historial_modelo_cargado.history\n",
        "\n",
        "#Mostramos las métricas del historial\n",
        "print(obtener_metricas_modelo_nuevo.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvbJ6e8D4v3a"
      },
      "source": [
        "#Opcional\n",
        "Graficamos las metricas accuracy y loss de los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YX_k4YV4v3n"
      },
      "outputs": [],
      "source": [
        "#Trazamos la curva de pérdida obtenida durante el entrenamiento\n",
        "plt.plot(obtener_metricas_modelo_nuevo['loss'], 'ro--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.title('Curva de pérdida - Entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "#Trazamos la curva de precisión obtenida durante el entrenamiento\n",
        "plt.plot(obtener_metricas_modelo_nuevo['accuracy'], 'go--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Curva de precisión - Entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "#Trazamos la curva de pérdida y la curva de precisión para entrenamiento\n",
        "plt.plot(obtener_metricas_modelo_nuevo['loss'], 'ro--')\n",
        "plt.plot(obtener_metricas_modelo_nuevo['accuracy'], 'go--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida/Precisión')\n",
        "plt.title('Curva de precisión/pérdida - Entrenamiento')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6cq2RYa5Hta"
      },
      "source": [
        "#Opcional\n",
        "Graficamos las metricas accuracy y loss de los datos de validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5mlmPwR5Htw"
      },
      "outputs": [],
      "source": [
        "#Trazamos la curva de pérdida de validación obtenida durante el entrenamiento\n",
        "plt.plot(obtener_metricas_modelo_nuevo['val_loss'], 'ro--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.title('Curva de pérdida - Validación')\n",
        "plt.show()\n",
        "\n",
        "#Trazamos la curva de precisión de validación obtenida durante el entrenamiento\n",
        "plt.plot(obtener_metricas_modelo_nuevo['val_accuracy'], 'go--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Curva de precisión - Validación')\n",
        "plt.show()\n",
        "\n",
        "#Trazamos la curva de pérdida y la curva de precisión para validación\n",
        "plt.plot(obtener_metricas_modelo_nuevo['val_loss'], 'ro--')\n",
        "plt.plot(obtener_metricas_modelo_nuevo['val_accuracy'], 'go--')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida/Precisión')\n",
        "plt.title('Curva de precisión/pérdida - Validación')\n",
        "plt.show()"
      ]
    }
  ]
}